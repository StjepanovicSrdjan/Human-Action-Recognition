{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "cx4JpehGaQ1p"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model, Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Flatten, Masking, Dropout, LSTM\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "owAYmztPW8Ar"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/content/drive/MyDrive/ColabNotebookss/OpenPose/dataset_mp_F.csv\")\n",
    "df = df[df['label'].isin(['sitting', 'running', 'drinking', 'cycling', 'sleeping'])]\n",
    "df.to_csv('data_set_mp_srdcs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "re63SMTLiDj2"
   },
   "outputs": [],
   "source": [
    "def split_dataset(x, y, train_split=0.8, validation_split=0.1, join_validation=True, keypoints_num=18):\n",
    "    indices = np.array(range(len(x)))\n",
    "\n",
    "    train_size = round(train_split * len(y))\n",
    "    validation_size = round(validation_split * len(y))\n",
    "\n",
    "    random.seed(123)\n",
    "    # random.shuffle(indices)\n",
    "\n",
    "    validation_indice_bound = train_size + validation_size\n",
    "    train_indices = indices[0:train_size]\n",
    "    validation_indices = indices[train_size:validation_indice_bound]\n",
    "    test_indices = indices[validation_indice_bound:len(x)]\n",
    "\n",
    "    x_train = x[train_indices, :].reshape(-1, keypoints_num, 2)\n",
    "    x_val = x[validation_indices, :].reshape(-1, keypoints_num, 2)\n",
    "    x_test = x[test_indices, :].reshape(-1, keypoints_num, 2)\n",
    "    y_train = y[train_indices, :]\n",
    "    y_val = y[validation_indices, :]\n",
    "    y_test = y[test_indices, :]\n",
    "\n",
    "    if join_validation:\n",
    "        x_test = np.concatenate((x_test, x_val), axis=0)\n",
    "        y_test = np.concatenate((y_test, y_val), axis=0)\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "d0EafvA5iH34"
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    df = pd.read_csv(\"/content/drive/MyDrive/ColabNotebookss/OpenPose/data_set_mp_srdcs.csv\")\n",
    "    if ('Unnamed: 0' in df.columns):\n",
    "      df = df.drop('Unnamed: 0', axis=1)\n",
    "    y_df = pd.get_dummies(df[\"label\"])\n",
    "    classes = y_df.columns\n",
    "    x_df = df.drop(\"label\", axis=1)\n",
    "\n",
    "    return x_df.to_numpy(), y_df.to_numpy(), classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "Qeq6JUQ0iKRc"
   },
   "outputs": [],
   "source": [
    "def get_data(join_validation, keypoints_num):\n",
    "    data_x, data_y, classes = load_dataset()\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = split_dataset(data_x, data_y, join_validation=join_validation, keypoints_num=keypoints_num)\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "zPnUZvogiMq4"
   },
   "outputs": [],
   "source": [
    "def train_nn(x_train, y_train, x_val, y_val, save_model=False, verbose=True, keypoints_num=18):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(batch_input_shape=(None, keypoints_num, 2), dtype=\"float32\"))\n",
    "\n",
    "    model.add(Flatten(data_format=\"channels_last\"))\n",
    "\n",
    "    model.add(Dense(units=64, activation=\"relu\"))\n",
    "    model.add(Dense(units=128, activation=\"relu\"))\n",
    "    model.add(Dense(units=512, activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=128, activation=\"relu\"))\n",
    "    model.add(Dense(units=128, activation=\"relu\"))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, batch_size=16, validation_data = (x_val, y_val), epochs=200, verbose=verbose)\n",
    "\n",
    "\n",
    "    if save_model:\n",
    "        model.save(\"/content/drive/MyDrive/ColabNotebookss/OpenPose/HAR_model\")\n",
    "\n",
    "    predictions = tf.argmax(model.predict(x_val), axis=1).numpy()\n",
    "\n",
    "    print(classification_report(tf.argmax(y_val, axis=1).numpy(), predictions))\n",
    "    print(f1_score(tf.argmax(y_val, axis=1).numpy(), predictions, average=\"micro\"))\n",
    "    # print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "N_WakPmqmdMf"
   },
   "outputs": [],
   "source": [
    "def train_svm(x_train, y_train, x_val, y_val, verbose=True, save_model=False, keypoints_num=18):\n",
    "    y_1d = tf.argmax(y_train, axis=1).numpy()\n",
    "    x_train = x_train.reshape((x_train.shape[0], keypoints_num * 2))\n",
    "    x_val = x_val.reshape((x_val.shape[0], keypoints_num * 2))\n",
    "\n",
    "    clf = SVC(kernel=\"rbf\", verbose=verbose)\n",
    "    clf.fit(x_train, y_1d)\n",
    "    predictions = clf.predict(x_val)\n",
    "\n",
    "    print(classification_report(tf.argmax(y_val, axis=1).numpy(), predictions))\n",
    "    print(f1_score(tf.argmax(y_val, axis=1).numpy(), predictions, average=\"micro\"))\n",
    "\n",
    "    if save_model:\n",
    "        with open(\"svm.pickle\", \"wb\") as file:\n",
    "            pickle.dump(clf, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "m0kVfDzaJCPG"
   },
   "outputs": [],
   "source": [
    "def train_random_forest(x_train, y_train, x_val, y_val, verbose=True, save_model=False, keypoints_num=18):\n",
    "    y_1d = tf.argmax(y_train, axis=1).numpy()\n",
    "    x_train = x_train.reshape((x_train.shape[0], keypoints_num * 2))\n",
    "    x_val = x_val.reshape((x_val.shape[0], keypoints_num * 2))\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=500, max_depth=100, verbose=verbose, n_jobs=-1, random_state=123)\n",
    "    clf.fit(x_train, y_1d)\n",
    "    predictions = clf.predict(x_val)\n",
    "\n",
    "    print(classification_report(tf.argmax(y_val, axis=1).numpy(), predictions))\n",
    "    print(f1_score(tf.argmax(y_val, axis=1).numpy(), predictions, average=\"micro\"))\n",
    "\n",
    "    if save_model:\n",
    "        with open(\"random_forest.pickle\", \"wb\") as file:\n",
    "            pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vwIkHRJ14Djf",
    "outputId": "65a075f4-2867-4cbb-fb9a-2181cf2efb0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.33      0.35        76\n",
      "           1       0.64      0.58      0.61        76\n",
      "           2       0.52      0.42      0.46        76\n",
      "           3       0.33      0.41      0.36        68\n",
      "           4       0.43      0.52      0.47        62\n",
      "\n",
      "    accuracy                           0.45       358\n",
      "   macro avg       0.46      0.45      0.45       358\n",
      "weighted avg       0.46      0.45      0.45       358\n",
      "\n",
      "0.44972067039106145\n",
      "Index(['cycling', 'drinking', 'running', 'sitting', 'sleeping'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test, classes = get_data(False, 33)\n",
    "# train_nn(x_train, y_train, x_test, y_test, save_model=True, verbose=False, keypoints_num=33)\n",
    "# train_svm(x_train, y_train, x_test, y_test, save_model=True, verbose=False, keypoints_num=33)\n",
    "train_random_forest(x_train, y_train, x_test, y_test, save_model=True, verbose=False, keypoints_num=33)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H49w-DEp4HON"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
