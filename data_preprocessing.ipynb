{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T5m8g9-L3pa",
        "outputId": "2ccaed3d-b8b1-408d-b035-0b6f815c7214"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.5.26)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.23.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.9 sounddevice-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UpzjIn4OPImY"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import time\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import pandas as pd\n",
        "import os\n",
        "import mediapipe as mp\n",
        "from random import randint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nPoints = 18\n",
        "protoFile = \"/content/drive/MyDrive/ColabNotebookss/OpenPose/pose_deploy_linevec.prototxt\"\n",
        "weightsFile = \"/content/drive/MyDrive/ColabNotebookss/OpenPose/pose_iter_440000.caffemodel\"\n",
        "keypointsMapping = ['Nose', 'Neck', 'R-Sho', 'R-Elb', 'R-Wr', 'L-Sho',\n",
        "                    'L-Elb', 'L-Wr', 'R-Hip', 'R-Knee', 'R-Ank', 'L-Hip',\n",
        "                    'L-Knee', 'L-Ank', 'R-Eye', 'L-Eye', 'R-Ear', 'L-Ear']\n",
        "\n",
        "POSE_PAIRS = [[1,2], [1,5], [2,3], [3,4], [5,6], [6,7],\n",
        "              [1,8], [8,9], [9,10], [1,11], [11,12], [12,13],\n",
        "              [1,0], [0,14], [14,16], [0,15], [15,17],\n",
        "              [2,17], [5,16] ]\n",
        "\n",
        "# index of pafs correspoding to the POSE_PAIRS\n",
        "# e.g for POSE_PAIR(1,2), the PAFs are located at indices (31,32) of output, Similarly, (1,5) -> (39,40) and so on.\n",
        "mapIdx = [[31,32], [39,40], [33,34], [35,36], [41,42], [43,44],\n",
        "          [19,20], [21,22], [23,24], [25,26], [27,28], [29,30],\n",
        "          [47,48], [49,50], [53,54], [51,52], [55,56],\n",
        "          [37,38], [45,46]]\n",
        "\n",
        "colors = [ [0,100,255], [0,100,255], [0,255,255], [0,100,255], [0,255,255], [0,100,255],\n",
        "         [0,255,0], [255,200,100], [255,0,255], [0,255,0], [255,200,100], [255,0,255],\n",
        "         [0,0,255], [255,0,0], [200,200,0], [255,0,0], [200,200,0], [0,0,0]]\n",
        "\n",
        "columns = ['label', 'coordinate 0', 'coordinate 1', 'coordinate 2', 'coordinate 3', 'coordinate 4', 'coordinate 5', 'coordinate 6', 'coordinate 7',\n",
        "          'coordinate 8', 'coordinate 9', 'coordinate 10', 'coordinate 11', 'coordinate 12', 'coordinate 13', 'coordinate 14', 'coordinate 15', 'coordinate 16',\n",
        "          'coordinate 17', 'coordinate 18', 'coordinate 19', 'coordinate 20', 'coordinate 21', 'coordinate 22', 'coordinate 23', 'coordinate 24', 'coordinate 25',\n",
        "          'coordinate 26', 'coordinate 27', 'coordinate 28', 'coordinate 29', 'coordinate 30', 'coordinate 31', 'coordinate 32', 'coordinate 33', 'coordinate 34',\n",
        "          'coordinate 35']"
      ],
      "metadata": {
        "id": "3ZZkQOCvlZVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getKeypoints(probMap, threshold=0.1):\n",
        "\n",
        "    mapSmooth = cv.GaussianBlur(probMap,(3,3),0,0)\n",
        "\n",
        "    mapMask = np.uint8(mapSmooth>threshold)\n",
        "    keypoints = []\n",
        "\n",
        "    #find the blobs\n",
        "    contours, _ = cv.findContours(mapMask, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    #for each blob find the maxima\n",
        "    for cnt in contours:\n",
        "        blobMask = np.zeros(mapMask.shape)\n",
        "        blobMask = cv.fillConvexPoly(blobMask, cnt, 1)\n",
        "        maskedProbMap = mapSmooth * blobMask\n",
        "        _, maxVal, _, maxLoc = cv.minMaxLoc(maskedProbMap)\n",
        "        keypoints.append(maxLoc + (probMap[maxLoc[1], maxLoc[0]],))\n",
        "\n",
        "    return keypoints"
      ],
      "metadata": {
        "id": "rNUCD5xplb8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getValidPairs(output, frameWidth, frameHeight, detected_keypoints):\n",
        "    valid_pairs = []\n",
        "    invalid_pairs = []\n",
        "    n_interp_samples = 10\n",
        "    paf_score_th = 0.1\n",
        "    conf_th = 0.7\n",
        "    # loop for every POSE_PAIR\n",
        "    for k in range(len(mapIdx)):\n",
        "        # A->B constitute a limb\n",
        "        pafA = output[0, mapIdx[k][0], :, :]\n",
        "        pafB = output[0, mapIdx[k][1], :, :]\n",
        "        pafA = cv.resize(pafA, (frameWidth, frameHeight))\n",
        "        pafB = cv.resize(pafB, (frameWidth, frameHeight))\n",
        "\n",
        "        # Find the keypoints for the first and second limb\n",
        "        candA = detected_keypoints[POSE_PAIRS[k][0]]\n",
        "        candB = detected_keypoints[POSE_PAIRS[k][1]]\n",
        "        nA = len(candA)\n",
        "        nB = len(candB)\n",
        "\n",
        "        # If keypoints for the joint-pair is detected\n",
        "        # check every joint in candA with every joint in candB\n",
        "        # Calculate the distance vector between the two joints\n",
        "        # Find the PAF values at a set of interpolated points between the joints\n",
        "        # Use the above formula to compute a score to mark the connection valid\n",
        "\n",
        "        if( nA != 0 and nB != 0):\n",
        "            valid_pair = np.zeros((0,3))\n",
        "            for i in range(nA):\n",
        "                max_j=-1\n",
        "                maxScore = -1\n",
        "                found = 0\n",
        "                for j in range(nB):\n",
        "                    # Find d_ij\n",
        "                    d_ij = np.subtract(candB[j][:2], candA[i][:2])\n",
        "                    norm = np.linalg.norm(d_ij)\n",
        "                    if norm:\n",
        "                        d_ij = d_ij / norm\n",
        "                    else:\n",
        "                        continue\n",
        "                    # Find p(u)\n",
        "                    interp_coord = list(zip(np.linspace(candA[i][0], candB[j][0], num=n_interp_samples),\n",
        "                                            np.linspace(candA[i][1], candB[j][1], num=n_interp_samples)))\n",
        "                    # Find L(p(u))\n",
        "                    paf_interp = []\n",
        "                    for k in range(len(interp_coord)):\n",
        "                        paf_interp.append([pafA[int(round(interp_coord[k][1])), int(round(interp_coord[k][0]))],\n",
        "                                           pafB[int(round(interp_coord[k][1])), int(round(interp_coord[k][0]))] ])\n",
        "                    # Find E\n",
        "                    paf_scores = np.dot(paf_interp, d_ij)\n",
        "                    avg_paf_score = sum(paf_scores)/len(paf_scores)\n",
        "\n",
        "                    # Check if the connection is valid\n",
        "                    # If the fraction of interpolated vectors aligned with PAF is higher then threshold -> Valid Pair\n",
        "                    if ( len(np.where(paf_scores > paf_score_th)[0]) / n_interp_samples ) > conf_th :\n",
        "                        if avg_paf_score > maxScore:\n",
        "                            max_j = j\n",
        "                            maxScore = avg_paf_score\n",
        "                            found = 1\n",
        "                # Append the connection to the list\n",
        "                if found:\n",
        "                    valid_pair = np.append(valid_pair, [[candA[i][3], candB[max_j][3], maxScore]], axis=0)\n",
        "\n",
        "            # Append the detected connections to the global list\n",
        "            valid_pairs.append(valid_pair)\n",
        "        else: # If no keypoints are detected\n",
        "            # print(\"No Connection : k = {}\".format(k))\n",
        "            invalid_pairs.append(k)\n",
        "            valid_pairs.append([])\n",
        "    #print(valid_pairs)\n",
        "    return valid_pairs, invalid_pairs"
      ],
      "metadata": {
        "id": "O4NwuEwoleqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function creates a list of keypoints belonging to each person\n",
        "# For each detected valid pair, it assigns the joint(s) to a person\n",
        "# It finds the person and index at which the joint should be added. This can be done since we have an id for each joint\n",
        "def getPersonwiseKeypoints(valid_pairs, invalid_pairs, keypoints_list):\n",
        "    # the last number in each row is the overall score\n",
        "    personwiseKeypoints = -1 * np.ones((0, 19))\n",
        "\n",
        "    for k in range(len(mapIdx)):\n",
        "        if k not in invalid_pairs:\n",
        "            partAs = valid_pairs[k][:,0]\n",
        "            partBs = valid_pairs[k][:,1]\n",
        "            indexA, indexB = np.array(POSE_PAIRS[k])\n",
        "\n",
        "            for i in range(len(valid_pairs[k])):\n",
        "                found = 0\n",
        "                person_idx = -1\n",
        "                for j in range(len(personwiseKeypoints)):\n",
        "                    if personwiseKeypoints[j][indexA] == partAs[i]:\n",
        "                        person_idx = j\n",
        "                        found = 1\n",
        "                        break\n",
        "\n",
        "                if found:\n",
        "                    personwiseKeypoints[person_idx][indexB] = partBs[i]\n",
        "                    personwiseKeypoints[person_idx][-1] += keypoints_list[partBs[i].astype(int), 2] + valid_pairs[k][i][2]\n",
        "\n",
        "                # if find no partA in the subset, create a new subset\n",
        "                elif not found and k < 17:\n",
        "                    row = -1 * np.ones(19)\n",
        "                    row[indexA] = partAs[i]\n",
        "                    row[indexB] = partBs[i]\n",
        "                    # add the keypoint_scores for the two keypoints and the paf_score\n",
        "                    row[-1] = sum(keypoints_list[valid_pairs[k][i,:2].astype(int), 2]) + valid_pairs[k][i][2]\n",
        "                    personwiseKeypoints = np.vstack([personwiseKeypoints, row])\n",
        "    return personwiseKeypoints"
      ],
      "metadata": {
        "id": "9eb8l09SlgzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect(img_path, net):\n",
        "    image1 = cv.imread(img_path)\n",
        "    image1 = cv.resize(image1, (240, 240))\n",
        "    frameWidth = image1.shape[1]\n",
        "    frameHeight = image1.shape[0]\n",
        "    # net = cv.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
        "    # net.setPreferableBackend(cv.dnn.DNN_TARGET_CPU)\n",
        "\n",
        "    inHeight = frameHeight\n",
        "    inWidth = frameWidth\n",
        "\n",
        "    inpBlob = cv.dnn.blobFromImage(image1, 1.0 / 255, (inWidth, inHeight),\n",
        "                              (0, 0, 0), swapRB=False, crop=False)\n",
        "\n",
        "    net.setInput(inpBlob)\n",
        "    output = net.forward()\n",
        "    i = 0\n",
        "    probMap = output[0, i, :, :]\n",
        "    probMap = cv.resize(probMap, (frameWidth, frameHeight))\n",
        "    detected_keypoints = []\n",
        "    keypoints_list = np.zeros((0,3))\n",
        "    keypoint_id = 0\n",
        "    threshold = 0.05\n",
        "\n",
        "    for part in range(nPoints):\n",
        "        probMap = output[0,part,:,:]\n",
        "        probMap = cv.resize(probMap, (image1.shape[1], image1.shape[0]))\n",
        "        keypoints = getKeypoints(probMap, threshold)\n",
        "        keypoints_with_id = []\n",
        "        for i in range(len(keypoints)):\n",
        "            keypoints_with_id.append(keypoints[i] + (keypoint_id,))\n",
        "            keypoints_list = np.vstack([keypoints_list, keypoints[i]])\n",
        "            keypoint_id += 1\n",
        "\n",
        "        detected_keypoints.append(keypoints_with_id)\n",
        "    frameClone = image1.copy()\n",
        "    valid_pairs, invalid_pairs = getValidPairs(output, frameWidth, frameHeight, detected_keypoints)\n",
        "    personwiseKeypoints = getPersonwiseKeypoints(valid_pairs, invalid_pairs, keypoints_list)\n",
        "    return keypoints_list, personwiseKeypoints, frameClone\n"
      ],
      "metadata": {
        "id": "uGJk5fIPltx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_dataset(path):\n",
        "    labels_df = pd.read_csv(\"/content/drive/MyDrive/ColabNotebookss/OpenPose/Training_set10to12.csv\");\n",
        "    net = cv.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
        "    # net.setPreferableBackend(cv.dnn.DNN_TARGET_CPU)\n",
        "    net.setPreferableBackend(cv.dnn.DNN_BACKEND_CUDA)\n",
        "    net.setPreferableTarget(cv.dnn.DNN_TARGET_CUDA)\n",
        "    output_df = pd.DataFrame(columns=columns)\n",
        "    for filename in labels_df['filename']:\n",
        "        row = []\n",
        "        file_path = os.path.join(path, filename)\n",
        "        label = labels_df[labels_df['filename'] == filename]['label'].values[0]\n",
        "        row.append(label)\n",
        "        key_list, personKeyPoints, _ = detect(file_path, net)\n",
        "        if len(personKeyPoints) == 0:\n",
        "            continue\n",
        "        index_of_min_list = min(range(len(personKeyPoints)), key=lambda i: list(personKeyPoints[i]).count(-1))\n",
        "        for i in range(18):\n",
        "            index = personKeyPoints[index_of_min_list][i]\n",
        "            if -1 == index:\n",
        "                row = row + [0, 0]\n",
        "                continue\n",
        "            point = np.int32(key_list[index.astype(int)])\n",
        "            row += [point[0], point[1]]\n",
        "        output_df.loc[len(output_df)] = row\n",
        "    output_df.to_csv('/content/drive/MyDrive/ColabNotebookss/OpenPose/HAR-dataset10to12.csv', index=False)\n",
        "    # for filename in os.listdir(path):\n",
        "    #     row = []\n",
        "    #     file_path = os.path.join(path, filename)\n",
        "    #     label = labels_df[labels_df['filename'] == filename]['label'].values[0]\n",
        "    #     row.append(label)\n",
        "    #     key_list, personKeyPoints, _ = detect(file_path, net)\n",
        "    #     if len(personKeyPoints) == 0:\n",
        "    #         continue\n",
        "    #     index_of_min_list = min(range(len(personKeyPoints)), key=lambda i: list(personKeyPoints[i]).count(-1))\n",
        "    #     for i in range(18):\n",
        "    #         index = personKeyPoints[index_of_min_list][i]\n",
        "    #         if -1 == index:\n",
        "    #             row = row + [0, 0]\n",
        "    #             continue\n",
        "    #         point = np.int32(key_list[index.astype(int)])\n",
        "    #         row += [point[0], point[1]]\n",
        "    #     output_df.loc[len(output_df)] = row\n",
        "    # output_df.to_csv('/content/drive/MyDrive/ColabNotebookss/OpenPose/HAR-datasetf.csv', index=False)\n"
      ],
      "metadata": {
        "id": "x2EVcvGmlvs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_dataset(\"/content/drive/MyDrive/ColabNotebookss/OpenPose/HumanActionRecognition/train\")"
      ],
      "metadata": {
        "id": "ZnNO4ptplzi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_mp = ['label', 'coordinate 0', 'coordinate 1', 'coordinate 2', 'coordinate 3', 'coordinate 4', 'coordinate 5', 'coordinate 6', 'coordinate 7',\n",
        "          'coordinate 8', 'coordinate 9', 'coordinate 10', 'coordinate 11', 'coordinate 12', 'coordinate 13', 'coordinate 14', 'coordinate 15', 'coordinate 16',\n",
        "          'coordinate 17', 'coordinate 18', 'coordinate 19', 'coordinate 20', 'coordinate 21', 'coordinate 22', 'coordinate 23', 'coordinate 24', 'coordinate 25',\n",
        "          'coordinate 26', 'coordinate 27', 'coordinate 28', 'coordinate 29', 'coordinate 30', 'coordinate 31', 'coordinate 32', 'coordinate 33', 'coordinate 34',\n",
        "          'coordinate 35', 'coordinate 36', 'coordinate 37', 'coordinate 38', 'coordinate 39', 'coordinate 40', 'coordinate 41', 'coordinate 42', 'coordinate 43',\n",
        "             'coordinate 44', 'coordinate 45', 'coordinate 46', 'coordinate 47', 'coordinate 48', 'coordinate 49', 'coordinate 50', 'coordinate 51', 'coordinate 52',\n",
        "             'coordinate 53', 'coordinate 54', 'coordinate 55', 'coordinate 56', 'coordinate 57', 'coordinate 58', 'coordinate 59', 'coordinate 60', 'coordinate 61',\n",
        "             'coordinate 62', 'coordinate 63', 'coordinate 64', 'coordinate 65']"
      ],
      "metadata": {
        "id": "cVMASuDdeaK_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_mediapipe(path):\n",
        "    labels_df = pd.read_csv(\"/content/drive/MyDrive/ColabNotebookss/OpenPose/HumanActionRecognition/Training_set.csv\");\n",
        "    mp_pose = mp.solutions.pose\n",
        "    pose = mp_pose.Pose()\n",
        "    output_df = pd.DataFrame(columns=columns_mp)\n",
        "    for filename in labels_df['filename']:\n",
        "        row = []\n",
        "        file_path = os.path.join(path, filename)\n",
        "        label = labels_df[labels_df['filename'] == filename]['label'].values[0]\n",
        "        row.append(label)\n",
        "        image = cv.imread(file_path)\n",
        "        image_rgb = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "        image_rgb = cv.resize(image_rgb, (240, 240))\n",
        "        results = pose.process(image_rgb)\n",
        "        if results.pose_landmarks:\n",
        "            landmarks = results.pose_landmarks.landmark\n",
        "            for landmark in landmarks:\n",
        "                height, width, _ = image.shape\n",
        "                x, y = landmark.x * width, landmark.y * height\n",
        "                row += [x, y]\n",
        "            output_df.loc[len(output_df)] = row\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    output_df.to_csv('dataset_mp_F.csv')"
      ],
      "metadata": {
        "id": "FeyxFvMRmFBo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_mediapipe(\"/content/drive/MyDrive/ColabNotebookss/OpenPose/HumanActionRecognition/train\")"
      ],
      "metadata": {
        "id": "V1jUwgV2M5RU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AmUNOY7NM_bT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}